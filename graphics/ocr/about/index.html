<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
	<base target="_blank">
	<title>Castleman-Lindbergh OCR</title>

	<!-- google font -->
	<link href="https://fonts.googleapis.com/css?family=Share+Tech+Mono" rel="stylesheet">
	<link rel="stylesheet" type="text/css" href="about.css">
</head>
<body>
	<h1>The Castleman-Lindbergh Digit Classifier</h1>
	<a class="linkback" target="_self" href=".."><div class="back">< Back to Classifier</div></a>
	<div>
		<img src="classifier.png" id="classifier" width="45%" border="5">

		<p>This classifier was built entirely by <a href="https://github.com/thomascastleman">Thomas Castleman</a> and <a href="https://github.com/johnnylindbergh">Johnny Lindbergh</a>.</p>

		<p>The processed input from the on-screen canvas is passed through a feed-forward neural network, which makes the classification. The network exists in a serialized state on the server, and is reconstructed client-side.</p>

		<p>The trained network was obtained using Castleman and Lindbergh's <a href="https://github.com/thomascastleman/fancy-regression">original classifier</a>, written in C, which was built to train on the <a href="http://yann.lecun.com/exdb/mnist/">MNIST database</a>.</p>

	</div>

	<br>
	<h3>Pre-processing</h3>

	<p>Before an image can be passed through the network, it must be compressed to a 28x28 resolution, to match the MNIST format.</p>

	<p>Upon request to classify, the image data from the canvas is reduced to this resolution by averaging the pixel intensity of subsections of the image (using the p5.js graphics library). This resulting image is then centered by its center of mass, to match the format of training data from MNIST.</p>

	<center>
		<figure>
			<img width="20%" src="pre.png">
			<img width="20%" src="post.png">
			<figcaption>Image before and after preprocessing.</figcaption>
		</figure>
	</center>

	<p>From here the image is vectorized and passed through the network.</p>

	<h3>The network</h3>

	<p>The current network in deployment has three layers, with 784 input neurons (28x28 images), 50 hidden neurons, and 10 output neurons. It was trained on 60,000 training pairs over 10 epochs, using batch gradient descent.</p>

	<p>Upon testing over 10,000 previously unseen pairs, the network achieved 89.1% accuracy overall.</p>

	<p>All functionality, including matrix operations, was implemented by Castleman and Lindbergh, and no libraries beyond the standard C libraries were used.</p>

	<a class="linkback" target="_self" href=".."><div class="back">< Back to Classifier</div></a>
</body>
</html>